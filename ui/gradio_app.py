import hashlib
import logging
import os
import shutil
import tempfile
import traceback
from typing import Any, Dict, Generator, Optional, Tuple

import gradio as gr
from langchain_community.document_loaders import TextLoader, Docx2txtLoader
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ä»ä¸Šçº§ç›®å½•å¯¼å…¥
from core.agent_builder import build_agent
from core.llm_services import embeddings

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def _default_session_state() -> Dict[str, Any]:
    return {
        "rag_retriever": None,
        "agent_executor": None,
        "last_index_cache_dir": None,
        "last_file_key": None,
        "agent_built_for_file_key": None,
    }


def _get_default_base_cache_dir() -> str:
    env_dir = os.getenv("RAG_FAISS_DIR")
    if env_dir and env_dir.strip():
        return os.path.expanduser(env_dir.strip())
    return os.path.join(os.path.expanduser("~"), ".rag_faiss_cache")


def _get_base_cache_dir(persist_dir_text: Optional[str]) -> str:
    base = (persist_dir_text or "").strip()
    if base:
        return os.path.expanduser(base)
    return _get_default_base_cache_dir()


def _file_cache_key(file_path: str) -> str:
    try:
        stat = os.stat(file_path)
        raw = f"{os.path.abspath(file_path)}::{stat.st_size}::{int(stat.st_mtime)}"
    except Exception:
        raw = os.path.abspath(file_path)
    return hashlib.sha1(raw.encode("utf-8")).hexdigest()


def _embeddings_fingerprint(obj: Any) -> str:
    parts = [type(obj).__name__]
    for attr in [
        "model",
        "model_name",
        "deployment",
        "deployment_name",
        "base_url",
        "endpoint",
        "encoding",
        "dimension",
    ]:
        val = getattr(obj, attr, None)
        if val is not None:
            parts.append(f"{attr}={val}")
    try:
        parts.append(repr(obj))
    except Exception:
        pass
    data = "|".join(parts).encode("utf-8", errors="ignore")
    return hashlib.sha1(data).hexdigest()


def _faiss_cache_dir_for(file_key: str, emb_fp: str, base_dir: str) -> str:
    base = base_dir
    os.makedirs(base, exist_ok=True)
    # ç›®å½•ååŒ…å« embeddings æŒ‡çº¹ï¼Œé¿å… embeddings å˜åŒ–å¯¼è‡´é”™é…
    return os.path.join(base, f"{file_key}__{emb_fp[:12]}")
def _ocr_pdf_to_temp(input_pdf_path: str) -> Optional[str]:
    """Try to OCR a PDF to a temporary searchable PDF. Returns path or None.
    Uses ocrmypdf Python API if available, else tries the `ocrmypdf` CLI.
    """
    try:
        # Prefer Python API if installed
        import ocrmypdf  # type: ignore
        tmp_dir = tempfile.mkdtemp(prefix="ocrpdf_")
        output_pdf_path = os.path.join(tmp_dir, "ocr_output.pdf")
        try:
            ocrmypdf.ocr(
                input_file=input_pdf_path,
                output_file=output_pdf_path,
                force_ocr=True,
                deskew=True,
                optimize=1,
                progress_bar=False,
            )
            if os.path.isfile(output_pdf_path) and os.path.getsize(output_pdf_path) > 0:
                return output_pdf_path
        except Exception:
            traceback.print_exc()
    except Exception:
        pass

    # Fallback to CLI if available
    try:
        import shutil as _sh
        if _sh.which("ocrmypdf"):
            tmp_dir = tempfile.mkdtemp(prefix="ocrpdf_")
            output_pdf_path = os.path.join(tmp_dir, "ocr_output.pdf")
            import subprocess
            cmd = [
                "ocrmypdf",
                "--force-ocr",
                "--deskew",
                "--optimize", "1",
                input_pdf_path,
                output_pdf_path,
            ]
            try:
                subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                if os.path.isfile(output_pdf_path) and os.path.getsize(output_pdf_path) > 0:
                    return output_pdf_path
            except Exception:
                traceback.print_exc()
    except Exception:
        pass

    return None

def _load_pdf_with_fallbacks(file_path: str):
    """Load PDF documents using multiple strategies to handle scanned or tricky PDFs.
    Returns a list[Document].
    """
    documents = []
    # 1) Try PyPDFLoader
    try:
        try:
            from langchain_community.document_loaders import PyPDFLoader
        except Exception:
            # fallback older path (some versions expose under .pdf)
            from langchain_community.document_loaders.pdf import PyPDFLoader  # type: ignore
        loader = PyPDFLoader(file_path)
        documents = loader.load()
        if documents:
            return documents
    except Exception:
        traceback.print_exc()

    # 2) Try PDFPlumberLoader if available
    try:
        from langchain_community.document_loaders import PDFPlumberLoader
        loader = PDFPlumberLoader(file_path)
        documents = loader.load()
        if documents:
            return documents
    except Exception:
        pass

    # 3) Try PyMuPDFLoader (fitz) if available
    try:
        from langchain_community.document_loaders import PyMuPDFLoader
        loader = PyMuPDFLoader(file_path)
        documents = loader.load()
        if documents:
            return documents
    except Exception:
        pass

    # 4) Lightweight fallback using pypdf directly
    try:
        from pypdf import PdfReader
        reader = PdfReader(file_path)
        texts = []
        for page in reader.pages:
            try:
                txt = page.extract_text() or ""
            except Exception:
                txt = ""
            if txt.strip():
                texts.append(txt)
        if texts:
            # Minimal Document structure to be compatible with splitters
            from langchain_core.documents import Document
            return [Document(page_content=t) for t in texts]
    except Exception:
        pass

    # 5) Try OCR to make it searchable, then reload
    try:
        ocr_path = _ocr_pdf_to_temp(file_path)
        if ocr_path:
            # Re-run fast loaders on OCR'd PDF
            try:
                from langchain_community.document_loaders import PDFPlumberLoader
                loader = PDFPlumberLoader(ocr_path)
                documents = loader.load()
                if documents:
                    return documents
            except Exception:
                pass
            try:
                from langchain_community.document_loaders import PyPDFLoader
                loader = PyPDFLoader(ocr_path)
                documents = loader.load()
                if documents:
                    return documents
            except Exception:
                pass
            # Fallback again to pypdf
            try:
                from pypdf import PdfReader
                reader = PdfReader(ocr_path)
                texts = []
                for page in reader.pages:
                    try:
                        txt = page.extract_text() or ""
                    except Exception:
                        txt = ""
                    if txt.strip():
                        texts.append(txt)
                if texts:
                    from langchain_core.documents import Document
                    return [Document(page_content=t) for t in texts]
            except Exception:
                pass
    except Exception:
        traceback.print_exc()

    return []



def _try_load_faiss_from_cache(cache_dir: str) -> Optional[FAISS]:
    try:
        if os.path.isdir(cache_dir):
            return FAISS.load_local(cache_dir, embeddings, allow_dangerous_deserialization=True)
    except Exception:
        traceback.print_exc()
    return None


def _save_faiss_to_cache(cache_dir: str, vs: FAISS) -> None:
    try:
        os.makedirs(cache_dir, exist_ok=True)
        vs.save_local(cache_dir)
    except Exception:
        traceback.print_exc()


def _safe_clear_directory(dir_path: str) -> None:
    try:
        if not os.path.isdir(dir_path):
            return
        # å°è¯•æ•´ä½“åˆ é™¤ï¼›å¤±è´¥åˆ™é€é¡¹åˆ é™¤
        try:
            shutil.rmtree(dir_path)
        except Exception:
            for name in os.listdir(dir_path):
                p = os.path.join(dir_path, name)
                try:
                    if os.path.isdir(p):
                        shutil.rmtree(p, ignore_errors=True)
                    else:
                        os.remove(p)
                except Exception:
                    traceback.print_exc()
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        os.makedirs(dir_path, exist_ok=True)
    except Exception:
        traceback.print_exc()


def process_uploaded_file(
    file_obj,
    state: Dict[str, Any],
    chunk_size: int,
    chunk_overlap: int,
    top_k: int,
    persist_dir_text: str,
    progress: gr.Progress = None,
) -> Generator[Tuple[str, Any, Dict[str, Any]], None, None]:
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œæ„å»ºå‘é‡ç´¢å¼•
    
    Args:
        file_obj: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
        state: ä¼šè¯çŠ¶æ€
        chunk_size: æ–‡æœ¬åˆ‡åˆ†å¤§å°
        chunk_overlap: æ–‡æœ¬åˆ‡åˆ†é‡å 
        top_k: æ£€ç´¢æ¡æ•°
        persist_dir_text: æŒä¹…åŒ–ç›®å½•
        
    Yields:
        (çŠ¶æ€æ¶ˆæ¯, UIæ›´æ–°, çŠ¶æ€å­—å…¸) å…ƒç»„
    """
    if not file_obj:
        logger.warning("æœªæä¾›æ–‡ä»¶å¯¹è±¡")
        if progress:
            progress(0.0, desc="é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ æ–‡ä»¶")
        status_html = "<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>âš ï¸ <b>æç¤ºï¼š</b>è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ TXT/PDF/DOCX æ ¼å¼ï¼‰</div>"
        result_html = "<div style='padding: 20px; border-radius: 10px; background-color: #ffe6e6; border: 3px solid #ff4444; text-align: center; font-size: 16px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>âŒ <b style='font-size: 18px; color: #d32f2f;'>ä¸Šä¼ å¤±è´¥</b><br><br><span style='font-size: 14px;'>è¯·å…ˆé€‰æ‹©æ–‡ä»¶åå†ç‚¹å‡»å¤„ç†æŒ‰é’®</span></div>"
        yield status_html, result_html, gr.update(interactive=True), state
        return

    try:
        logger.info(f"å¼€å§‹å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œchunk_size={chunk_size}, chunk_overlap={chunk_overlap}, top_k={top_k}")
        # ç»Ÿä¸€ä¸ºåˆ—è¡¨å¤„ç†
        files = file_obj if isinstance(file_obj, list) else [file_obj]

        base_cache_dir = _get_base_cache_dir(persist_dir_text)
        emb_fp = _embeddings_fingerprint(embeddings)

        # å¤šæ–‡ä»¶ä½¿ç”¨ä¼šè¯çº§åˆå¹¶ç›®å½•ï¼›å•æ–‡ä»¶ä»ä½¿ç”¨æ–‡ä»¶ç‰¹å®šç›®å½•
        if len(files) > 1:
            cache_dir = os.path.join(base_cache_dir, f"combined__{emb_fp[:12]}")
            file_key = "combined"
        else:
            try:
                single_path = files[0].name
            except Exception:
                single_path = str(files[0])
            file_key = _file_cache_key(single_path)
            cache_dir = _faiss_cache_dir_for(file_key, emb_fp, base_cache_dir)

        vs = _try_load_faiss_from_cache(cache_dir)

        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap
        )

        total_chunks = 0
        result_html = ""  # åˆå§‹åŒ–ç»“æœæç¤ºä¸ºç©º
        
        if vs:
            logger.info(f"ä»ç¼“å­˜åŠ è½½å‘é‡ç´¢å¼•: {cache_dir}")
            if progress:
                progress(0.1, desc="å·²ä»ç¼“å­˜åŠ è½½å‘é‡ç´¢å¼•")
            status_html = "<div style='padding: 15px; border-radius: 8px; background-color: #e6f3ff; border: 2px solid #4CAF50; text-align: center; font-size: 14px;'>ğŸ“¦ <b>æ­¥éª¤ 1/4ï¼š</b>å·²ä»ç¼“å­˜åŠ è½½å‘é‡ç´¢å¼•</div>"
            yield status_html, result_html, gr.update(interactive=False), state
        else:
            logger.info(f"å¼€å§‹åŠ è½½ {len(files)} ä¸ªæ–‡ä»¶")
            if progress:
                progress(0.05, desc="æ­£åœ¨åŠ è½½æ–‡æ¡£...")
            file_names = ", ".join([os.path.basename(f.name if hasattr(f, 'name') else str(f)) for f in files[:3]])
            if len(files) > 3:
                file_names += f" ç­‰ {len(files)} ä¸ªæ–‡ä»¶"
            status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>ğŸ“„ <b>æ­¥éª¤ 1/4ï¼š</b>æ­£åœ¨åŠ è½½æ–‡æ¡£...<br><small>æ–‡ä»¶ï¼š{file_names}</small></div>"
            yield status_html, result_html, gr.update(interactive=False), state

            total_files = len(files)
            for file_idx, f in enumerate(files):
                try:
                    file_path = f.name
                except Exception:
                    file_path = str(f)
                file_ext = os.path.splitext(file_path)[1].lower()
                file_name = os.path.basename(file_path)

                # æ›´æ–°è¿›åº¦ï¼šåŠ è½½æ–‡æ¡£é˜¶æ®µ (10% - 30%)
                if progress:
                    progress(0.1 + (file_idx / total_files) * 0.2, desc=f"æ­£åœ¨åŠ è½½æ–‡æ¡£ ({file_idx + 1}/{total_files}): {file_name}")

                # æ–‡ä»¶å¤§å°æç¤ºï¼ˆå°½åŠ›è€Œä¸ºï¼‰
                try:
                    size_mb = os.path.getsize(file_path) / (1024 * 1024)
                    if size_mb > 50:
                        warning_html = f"<div style='padding: 10px; border-radius: 5px; background-color: #fff3cd; border-left: 4px solid #ffc107;'>âš ï¸ <b>æç¤ºï¼š</b>{file_name} æ–‡ä»¶è¾ƒå¤§ï¼ˆçº¦{size_mb:.1f}MBï¼‰ï¼Œå¤„ç†å¯èƒ½è¾ƒæ…¢</div>"
                        yield warning_html, gr.update(interactive=False), state
                except Exception:
                    pass

                # åŠ è½½
                if file_ext == ".pdf":
                    documents = _load_pdf_with_fallbacks(file_path)
                    if not documents:
                        continue
                elif file_ext == ".txt":
                    loader = TextLoader(file_path, encoding="utf-8")
                    documents = loader.load()
                elif file_ext == ".docx":
                    loader = Docx2txtLoader(file_path)
                    documents = loader.load()
                else:
                    warning_html = f"<div style='padding: 10px; border-radius: 5px; background-color: #fff3cd; border-left: 4px solid #ffc107;'>âš ï¸ <b>è·³è¿‡ï¼š</b>ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ {file_ext}<br><small>æ–‡ä»¶ï¼š{file_name}</small></div>"
                    yield warning_html, gr.update(interactive=False), state
                    continue

                # æ›´æ–°è¿›åº¦ï¼šåˆ‡åˆ†æ–‡æ¡£é˜¶æ®µ (30% - 50%)
                if progress:
                    progress(0.3 + (file_idx / total_files) * 0.2, desc=f"æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£ ({file_idx + 1}/{total_files}): {file_name}")

                # åˆ‡åˆ†
                status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>âœ‚ï¸ <b>æ­¥éª¤ 2/4ï¼š</b>æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£...<br><small>æ–‡ä»¶ï¼š{file_name} ({file_idx + 1}/{total_files})</small></div>"
                yield status_html, result_html, gr.update(interactive=False), state
                chunks = splitter.split_documents(documents)
                if not chunks:
                    continue
                total_chunks += len(chunks)

                # æ›´æ–°è¿›åº¦ï¼šåˆ›å»ºå‘é‡ç´¢å¼•é˜¶æ®µ (50% - 80%)
                if progress:
                    progress(0.5 + (file_idx / total_files) * 0.3, desc=f"æ­£åœ¨ç”Ÿæˆå‘é‡ç´¢å¼• ({file_idx + 1}/{total_files}): {file_name}")

                # å»ºç´¢å¼•/è¿½åŠ 
                if vs is None:
                    logger.info(f"åˆ›å»ºå‘é‡ç´¢å¼•ï¼ŒåŒ…å« {len(chunks)} ä¸ªç‰‡æ®µ")
                    status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>ğŸ” <b>æ­¥éª¤ 3/4ï¼š</b>æ­£åœ¨åˆ›å»ºå‘é‡ç´¢å¼•...<br><small>ç”ŸæˆåµŒå…¥å‘é‡ä¸­ï¼Œè¯·ç¨å€™ï¼ˆåŒ…å« {len(chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µï¼‰</small></div>"
                    yield status_html, result_html, gr.update(interactive=False), state
                    vs = FAISS.from_documents(chunks, embeddings)
                else:
                    logger.info(f"è¿½åŠ  {len(chunks)} ä¸ªç‰‡æ®µåˆ°ç°æœ‰ç´¢å¼•")
                    status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>â• <b>æ­¥éª¤ 3/4ï¼š</b>è¿½åŠ åˆ°å‘é‡ç´¢å¼•...<br><small>æ–‡ä»¶ï¼š{file_name}ï¼ˆ{len(chunks)} ä¸ªç‰‡æ®µï¼‰</small></div>"
                    yield status_html, result_html, gr.update(interactive=False), state
                    vs.add_documents(chunks)

            if vs is None:
                if progress:
                    progress(1.0, desc="å¤„ç†å¤±è´¥ï¼šæœªèƒ½æå–æ–‡æœ¬å†…å®¹")
                status_html = "<div style='padding: 15px; border-radius: 8px; background-color: #ffe6e6; border: 2px solid #ff4444; text-align: center; font-size: 14px;'>âŒ <b>å¤„ç†å¤±è´¥ï¼š</b>æœªèƒ½ä»æ‰€é€‰æ–‡ä»¶ä¸­æå–ä»»ä½•æ–‡æœ¬å†…å®¹</div>"
                result_html = "<div style='padding: 20px; border-radius: 10px; background-color: #ffe6e6; border: 3px solid #ff4444; text-align: center; font-size: 16px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>âŒ <b style='font-size: 18px; color: #d32f2f;'>ä¸Šä¼ å¤±è´¥</b><br><br><span style='font-size: 14px;'>æœªèƒ½ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹</span><br><small style='color: #666; margin-top: 10px; display: block;'>ğŸ’¡ æç¤ºï¼šè‹¥ä¸ºæ‰«æç‰ˆPDFï¼Œè¯·å…ˆè¿›è¡ŒOCRå¤„ç†ï¼ˆä¾‹å¦‚ä½¿ç”¨OCRmyPDFï¼‰åå†å°è¯•</small></div>"
                yield status_html, result_html, gr.update(interactive=True), state
                return

            _save_faiss_to_cache(cache_dir, vs)
            logger.info(f"å‘é‡ç´¢å¼•å·²ä¿å­˜åˆ°: {cache_dir}")

        # æ›´æ–°è¿›åº¦ï¼šæ„å»º Agent é˜¶æ®µ (80% - 95%)
        if progress:
            progress(0.85, desc="æ­£åœ¨æ„å»ºæ™ºèƒ½ Agent...")

        # åˆ›å»ºæ£€ç´¢å™¨å’Œ Agent
        try:
            logger.info(f"åˆ›å»ºæ£€ç´¢å™¨ï¼Œtop_k={top_k}")
            status_html = "<div style='padding: 15px; border-radius: 8px; background-color: #fff4e6; border: 2px solid #FF9800; text-align: center; font-size: 14px;'>ğŸ¤– <b>æ­¥éª¤ 4/4ï¼š</b>æ­£åœ¨æ„å»ºæ™ºèƒ½ Agent...</div>"
            yield status_html, result_html, gr.update(interactive=False), state
            
            state["rag_retriever"] = vs.as_retriever(search_kwargs={"k": int(top_k)})
            logger.info("æ­£åœ¨æ„å»º Agent...")
            state["agent_executor"] = build_agent(state["rag_retriever"])
            state["last_index_cache_dir"] = cache_dir
            state["last_file_key"] = file_key
            state["agent_built_for_file_key"] = file_key
            logger.info("æ–‡ä»¶å¤„ç†å®Œæˆï¼ŒAgent å·²æ›´æ–°")
        except Exception as e:
            logger.error(f"æ„å»º Agent å¤±è´¥: {e}", exc_info=True)
            if progress:
                progress(1.0, desc="å¤„ç†å¤±è´¥")
            status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #ffe6e6; border: 2px solid #ff4444; text-align: center; font-size: 14px;'>âš ï¸ <b>éƒ¨åˆ†æˆåŠŸï¼š</b>æ–‡ä»¶å¤„ç†æˆåŠŸï¼Œä½† Agent æ„å»ºå¤±è´¥</div>"
            result_html = f"<div style='padding: 20px; border-radius: 10px; background-color: #fff3cd; border: 3px solid #ffc107; text-align: center; font-size: 16px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>âš ï¸ <b style='font-size: 18px; color: #f57c00;'>éƒ¨åˆ†æˆåŠŸ</b><br><br><span style='font-size: 14px;'>æ–‡ä»¶å¤„ç†æˆåŠŸï¼Œä½† Agent æ„å»ºå¤±è´¥</span><br><small style='color: #666; margin-top: 10px; display: block;'>é”™è¯¯ï¼š{str(e)}<br>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•</small></div>"
            yield status_html, result_html, gr.update(interactive=True), state
            return

        # æ›´æ–°è¿›åº¦ï¼šå®Œæˆ (100%)
        if progress:
            progress(1.0, desc="âœ… å¤„ç†å®Œæˆï¼ä¸Šä¼ æˆåŠŸ")

        if len(files) > 1:
            status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #e8f5e9; border: 2px solid #4CAF50; text-align: center; font-size: 14px;'>âœ… <b>å¤„ç†å®Œæˆï¼</b>å·²å¤„ç†å¹¶åˆå¹¶ {len(files)} ä¸ªæ–‡ä»¶</div>"
            result_html = f"<div style='padding: 25px; border-radius: 10px; background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%); border: 3px solid #4CAF50; text-align: center; font-size: 16px; box-shadow: 0 4px 12px rgba(76, 175, 80, 0.3);'>âœ… <b style='font-size: 22px; color: #2e7d32;'>ä¸Šä¼ æˆåŠŸï¼</b><br><br><div style='font-size: 15px; margin: 15px 0;'>å·²å¤„ç†å¹¶åˆå¹¶ <b style='color: #1b5e20;'>{len(files)}</b> ä¸ªæ–‡ä»¶<br>å…±ç”Ÿæˆ <b style='color: #1b5e20;'>{total_chunks}</b> ä¸ªæ–‡æœ¬ç‰‡æ®µ</div><div style='margin-top: 15px; padding-top: 15px; border-top: 2px solid #4CAF50;'><span style='font-size: 18px;'>ğŸ‰</span> <b style='color: #2e7d32;'>ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ï¼</b></div></div>"
            logger.info(f"å·²å¤„ç†å¹¶åˆå¹¶ {len(files)} ä¸ªæ–‡ä»¶ï¼ˆæ–°å¢ {total_chunks} ä¸ªç‰‡æ®µï¼‰")
            yield status_html, result_html, gr.update(interactive=True), state
        else:
            status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #e8f5e9; border: 2px solid #4CAF50; text-align: center; font-size: 14px;'>âœ… <b>å¤„ç†å®Œæˆï¼</b>æ–‡ä»¶ '{os.path.basename(single_path)}' å·²å¤„ç†</div>"
            result_html = f"<div style='padding: 25px; border-radius: 10px; background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%); border: 3px solid #4CAF50; text-align: center; font-size: 16px; box-shadow: 0 4px 12px rgba(76, 175, 80, 0.3);'>âœ… <b style='font-size: 22px; color: #2e7d32;'>ä¸Šä¼ æˆåŠŸï¼</b><br><br><div style='font-size: 15px; margin: 15px 0;'>æ–‡ä»¶ <b style='color: #1b5e20;'>'{os.path.basename(single_path)}'</b> å¤„ç†å®Œæˆ<br>å…±ç”Ÿæˆ <b style='color: #1b5e20;'>{total_chunks}</b> ä¸ªæ–‡æœ¬ç‰‡æ®µ</div><div style='margin-top: 15px; padding-top: 15px; border-top: 2px solid #4CAF50;'><span style='font-size: 18px;'>ğŸ‰</span> <b style='color: #2e7d32;'>ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ï¼</b></div></div>"
            logger.info(f"æ–‡ä»¶ '{os.path.basename(single_path)}' å¤„ç†æˆåŠŸï¼")
            yield status_html, result_html, gr.update(interactive=True), state

    except Exception as e:
        if progress:
            progress(1.0, desc="å¤„ç†å¤±è´¥")
        status_html = f"<div style='padding: 15px; border-radius: 8px; background-color: #ffe6e6; border: 2px solid #ff4444; text-align: center; font-size: 14px;'>âŒ <b>å¤„ç†å¤±è´¥ï¼š</b>{str(e)[:50]}...</div>"
        result_html = f"<div style='padding: 25px; border-radius: 10px; background: linear-gradient(135deg, #ffe6e6 0%, #ffcdd2 100%); border: 3px solid #ff4444; text-align: center; font-size: 16px; box-shadow: 0 4px 12px rgba(244, 67, 54, 0.3);'>âŒ <b style='font-size: 22px; color: #d32f2f;'>ä¸Šä¼ å¤±è´¥</b><br><br><div style='font-size: 15px; margin: 15px 0; color: #c62828;'>{str(e)}</div><div style='margin-top: 15px; padding-top: 15px; border-top: 2px solid #ff4444;'><small style='color: #666;'>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯</small></div></div>"
        logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)
        yield status_html, result_html, gr.update(interactive=True), state


def chat_with_agent(question: str, history: list, state: Dict[str, Any]) -> str:
    """
    ä¸ Agent è¿›è¡Œå¯¹è¯
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        history: å¯¹è¯å†å²
        state: ä¼šè¯çŠ¶æ€
        
    Returns:
        Agent çš„å›ç­”
    """
    if not question or not question.strip():
        logger.warning("æ”¶åˆ°ç©ºé—®é¢˜")
        return "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚"
    
    logger.info(f"æ”¶åˆ°é—®é¢˜: {question[:100]}...")
    
    agent = state.get("agent_executor")
    retriever = state.get("rag_retriever")
    last_file_key = state.get("last_file_key")
    built_for_key = state.get("agent_built_for_file_key")

    needs_rebuild = False
    if agent is None:
        logger.info("Agent æœªåˆå§‹åŒ–ï¼Œéœ€è¦æ„å»º")
        needs_rebuild = True
    elif last_file_key and last_file_key != built_for_key:
        # æ–‡ä»¶å˜åŒ–ï¼Œéœ€é‡å»ºä»¥å¯ç”¨æœ€æ–°RAG
        logger.info("æ–‡ä»¶å·²æ›´æ–°ï¼Œéœ€è¦é‡å»º Agent")
        needs_rebuild = True

    if needs_rebuild:
        try:
            logger.info("æ­£åœ¨é‡å»º Agent...")
            agent = build_agent(retriever)
            state["agent_executor"] = agent
            state["agent_built_for_file_key"] = last_file_key
            logger.info("Agent é‡å»ºæˆåŠŸ")
        except Exception as e:
            logger.error(f"Agentåˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            return f"Agentåˆå§‹åŒ–å¤±è´¥: {e}ã€‚è¯·å°è¯•é‡æ–°ä¸Šä¼ æ–‡æ¡£ã€‚"
    
    try:
        logger.debug("è°ƒç”¨ Agent å¤„ç†é—®é¢˜...")
        response = agent.invoke({"input": question})
        output = response.get("output", "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¾—åˆ°æœ‰æ•ˆçš„å›ç­”ã€‚")
        logger.info("Agent å›ç­”ç”ŸæˆæˆåŠŸ")
        return output
    except Exception as e:
        logger.error(f"Agent å¤„ç†é—®é¢˜å¤±è´¥: {e}", exc_info=True)
        return f"å‘ç”Ÿé”™è¯¯: {e}ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚"


def process_more_files(
    files,
    state: Dict[str, Any],
    chunk_size: int,
    chunk_overlap: int,
    top_k: int,
    persist_dir_text: str,
) -> Generator[Tuple[str, Dict[str, Any]], None, None]:
    """
    è¿½åŠ ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œå°†å†…å®¹åˆå¹¶åˆ°å½“å‰å‘é‡ç´¢å¼•ä¸­ã€‚
    
    Args:
        files: è¦è¿½åŠ çš„æ–‡ä»¶åˆ—è¡¨
        state: ä¼šè¯çŠ¶æ€
        chunk_size: æ–‡æœ¬åˆ‡åˆ†å¤§å°
        chunk_overlap: æ–‡æœ¬åˆ‡åˆ†é‡å 
        top_k: æ£€ç´¢æ¡æ•°
        persist_dir_text: æŒä¹…åŒ–ç›®å½•
        
    Yields:
        (çŠ¶æ€æ¶ˆæ¯, çŠ¶æ€å­—å…¸) å…ƒç»„
    """
    if not files:
        logger.warning("æœªæä¾›è¦è¿½åŠ çš„æ–‡ä»¶")
        yield "è¯·å…ˆé€‰æ‹©è¦è¿½åŠ çš„æ–‡ä»¶ã€‚", state
        return

    try:
        logger.info(f"å¼€å§‹è¿½åŠ  {len(files) if isinstance(files, list) else 1} ä¸ªæ–‡ä»¶åˆ°ç°æœ‰ç´¢å¼•")
        base_cache_dir = _get_base_cache_dir(persist_dir_text)
        emb_fp = _embeddings_fingerprint(embeddings)

        # ä¼˜å…ˆä½¿ç”¨ç°æœ‰ç´¢å¼•ç›®å½•
        cache_dir = state.get("last_index_cache_dir")
        if not cache_dir or not os.path.isdir(cache_dir):
            # ä½¿ç”¨ä¸€ä¸ªç¨³å®šçš„â€œä¼šè¯åˆå¹¶â€ç›®å½•
            cache_dir = os.path.join(base_cache_dir, f"combined__{emb_fp[:12]}")

        # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
        vs = _try_load_faiss_from_cache(cache_dir)

        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap
        )

        total_chunks = 0
        for f in files:
            try:
                file_path = f.name
            except Exception:
                file_path = str(f)
            file_ext = os.path.splitext(file_path)[1].lower()
            status_html = f"<div style='padding: 10px; border-radius: 5px; background-color: #fff4e6; border-left: 4px solid #FF9800;'>ğŸ“„ <b>æ­£åœ¨å¤„ç†ï¼š</b>{os.path.basename(file_path)}...</div>"
            yield status_html, state

            # åŠ è½½æ–‡æ¡£
            if file_ext == ".pdf":
                documents = _load_pdf_with_fallbacks(file_path)
                if not documents:
                    continue
            elif file_ext == ".txt":
                loader = TextLoader(file_path, encoding="utf-8")
                documents = loader.load()
            elif file_ext == ".docx":
                loader = Docx2txtLoader(file_path)
                documents = loader.load()
            else:
                continue

            # åˆ‡åˆ†
            chunks = splitter.split_documents(documents)
            if not chunks:
                continue
            total_chunks += len(chunks)

            # åˆ›å»ºæˆ–è¿½åŠ åˆ°ç´¢å¼•
            if vs is None:
                vs = FAISS.from_documents(chunks, embeddings)
            else:
                vs.add_documents(chunks)

        if vs is None:
            error_html = "<div style='padding: 10px; border-radius: 5px; background-color: #ffe6e6; border-left: 4px solid #ff4444;'>âŒ <b>è¿½åŠ å¤±è´¥ï¼š</b>æœªèƒ½ä»æ‰€é€‰æ–‡ä»¶ä¸­æå–å¯ç”¨æ–‡æœ¬å†…å®¹<br><small>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–å†…å®¹æ˜¯å¦æ­£ç¡®</small></div>"
            yield error_html, state
            return

        # ä¿å­˜å¹¶æ›´æ–°ä¼šè¯
        _save_faiss_to_cache(cache_dir, vs)
        logger.info(f"å‘é‡ç´¢å¼•å·²ä¿å­˜åˆ°: {cache_dir}")
        
        try:
            status_html = "<div style='padding: 10px; border-radius: 5px; background-color: #fff4e6; border-left: 4px solid #FF9800;'>ğŸ¤– <b>æœ€åä¸€æ­¥ï¼š</b>æ­£åœ¨æ›´æ–°æ™ºèƒ½ Agent...</div>"
            yield status_html, state
            
            state["rag_retriever"] = vs.as_retriever(search_kwargs={"k": int(top_k)})
            state["agent_executor"] = build_agent(state["rag_retriever"])
            state["last_index_cache_dir"] = cache_dir
            state["last_file_key"] = "combined"
            state["agent_built_for_file_key"] = "combined"
            logger.info("æ–‡ä»¶è¿½åŠ å®Œæˆï¼ŒAgent å·²æ›´æ–°")
        except Exception as e:
            logger.error(f"æ„å»º Agent å¤±è´¥: {e}", exc_info=True)
            error_html = f"<div style='padding: 10px; border-radius: 5px; background-color: #ffe6e6; border-left: 4px solid #ff4444;'>âš ï¸ <b>éƒ¨åˆ†æˆåŠŸï¼š</b>æ–‡ä»¶è¿½åŠ æˆåŠŸï¼Œä½† Agent æ„å»ºå¤±è´¥<br><small>é”™è¯¯ï¼š{str(e)}<br>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•</small></div>"
            yield error_html, state
            return

        success_msg = f"âœ… <b>è¿½åŠ æˆåŠŸï¼</b><br>å·²è¿½åŠ  <b>{total_chunks}</b> ä¸ªæ–‡æœ¬ç‰‡æ®µåˆ°ç°æœ‰ç´¢å¼•<br><small>ğŸ‰ æ–°æ–‡æ¡£å·²ç”Ÿæ•ˆï¼Œå¯ä»¥å¼€å§‹æé—®äº†ï¼</small>"
        success_html = f"<div style='padding: 15px; border-radius: 5px; background-color: #e8f5e9; border-left: 4px solid #4CAF50;'>{success_msg}</div>"
        logger.info(f"å·²è¿½åŠ å®Œæˆï¼ˆæ–°å¢ {total_chunks} ä¸ªç‰‡æ®µï¼‰")
        yield success_html, state

    except Exception as e:
        error_msg = f"âŒ <b>è¿½åŠ å¤±è´¥ï¼š</b>{str(e)}<br><small>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯</small>"
        error_html = f"<div style='padding: 15px; border-radius: 5px; background-color: #ffe6e6; border-left: 4px solid #ff4444;'>{error_msg}</div>"
        logger.error(f"è¿½åŠ å¤±è´¥: {e}", exc_info=True)
        yield error_html, state


def clear_cache(persist_dir_text: str, state: Dict[str, Any]):
    """
    æ¸…ç†ç¼“å­˜å¹¶é‡ç½® Agent
    
    Args:
        persist_dir_text: æŒä¹…åŒ–ç›®å½•
        state: ä¼šè¯çŠ¶æ€
        
    Returns:
        (çŠ¶æ€æ¶ˆæ¯, çŠ¶æ€å­—å…¸) å…ƒç»„
    """
    try:
        base_cache_dir = _get_base_cache_dir(persist_dir_text)
        logger.info(f"æ­£åœ¨æ¸…ç†ç¼“å­˜ç›®å½•: {base_cache_dir}")
        _safe_clear_directory(base_cache_dir)
        # é‡ç½®ä¼šè¯ä¸­çš„ RAG çŠ¶æ€
        state["rag_retriever"] = None
        state["agent_executor"] = build_agent(None)
        state["last_index_cache_dir"] = None
        state["last_file_key"] = None
        logger.info("ç¼“å­˜å·²æ¸…ç†ï¼ŒAgent å·²é‡ç½®")
        success_html = "<div style='padding: 15px; border-radius: 5px; background-color: #e8f5e9; border-left: 4px solid #4CAF50;'>âœ… <b>æ¸…ç†æˆåŠŸï¼</b><br>ç¼“å­˜å·²æ¸…ç†ï¼ŒAgent å·²é‡ç½®ä¸ºæ— RAGæ¨¡å¼<br><small>ğŸ’¡ æç¤ºï¼šå¦‚éœ€ä½¿ç”¨æ–‡æ¡£æ£€ç´¢åŠŸèƒ½ï¼Œè¯·é‡æ–°ä¸Šä¼ æ–‡æ¡£</small></div>"
        return success_html, state
    except Exception as e:
        error_msg = f"âŒ <b>æ¸…ç†å¤±è´¥ï¼š</b>{str(e)}<br><small>ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç›®å½•æƒé™æˆ–ç¨åé‡è¯•</small>"
        error_html = f"<div style='padding: 15px; border-radius: 5px; background-color: #ffe6e6; border-left: 4px solid #ff4444;'>{error_msg}</div>"
        logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
        return error_html, state


def build_ui():
    with gr.Blocks(theme=gr.themes.Soft(), title="ç”µä¿¡è¡Œä¸šæ™ºèƒ½å¯¹è¯ç³»ç»Ÿ") as demo:
        session_state = gr.State(_default_session_state())

        gr.Markdown("# ç”µä¿¡è¡Œä¸šæ™ºèƒ½å¯¹è¯ç³»ç»Ÿç”±LangChain + é€šä¹‰åƒé—® + Neo4j + RAGé©±åŠ¨")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### â–² ä¸Šä¼ ä¸šåŠ¡æ–‡æ¡£")

                file_uploader = gr.File(
                    label="é€‰æ‹©æˆ–æ‹–æ‹½æ–‡ä»¶ (æ”¯æŒå¤šé€‰ï¼šTXT/PDF/DOCX)",
                    file_types=[".txt", ".pdf", ".docx"],
                    file_count="multiple",
                )

                with gr.Row():
                    chunk_size = gr.Slider(
                        minimum=200,
                        maximum=2000,
                        value=500,
                        step=50,
                        label="åˆ‡åˆ†ç‰‡æ®µå¤§å° (chunk_size)",
                    )
                    chunk_overlap = gr.Slider(
                        minimum=0,
                        maximum=400,
                        value=50,
                        step=10,
                        label="åˆ‡åˆ†é‡å  (chunk_overlap)",
                    )

                top_k = gr.Slider(
                    minimum=1,
                    maximum=10,
                    value=3,
                    step=1,
                    label="æ£€ç´¢æ¡æ•° (top_k)",
                )

                with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                    persist_dir = gr.Textbox(
                        label="ç´¢å¼•æŒä¹…åŒ–ç›®å½• (ç•™ç©ºä½¿ç”¨ RAG_FAISS_DIR æˆ– ~/.rag_faiss_cache)",
                        value=_get_default_base_cache_dir(),
                    )
                    clear_cache_btn = gr.Button("æ¸…ç†ç¼“å­˜", variant="secondary")

                process_button = gr.Button("å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶", variant="primary", size="lg")
                
                # çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ - æ›´é†’ç›®
                status_display = gr.Markdown(
                    value="<div style='padding: 15px; border-radius: 8px; background-color: #f5f5f5; border: 2px solid #e0e0e0; text-align: center; font-size: 14px;'>ğŸ“‹ <b>çŠ¶æ€ï¼š</b>ç­‰å¾…ä¸Šä¼ æ–‡ä»¶...</div>",
                    label="ğŸ“Š æ–‡ä»¶å¤„ç†çŠ¶æ€",
                    visible=True
                )
                
                # æˆåŠŸ/å¤±è´¥æç¤ºæ¡† - ç‹¬ç«‹æ˜¾ç¤ºï¼Œæ›´åŠ é†’ç›®
                result_display = gr.Markdown(
                    value="",
                    visible=True,
                    label="ğŸ“¢ å¤„ç†ç»“æœ",
                    elem_classes=["result-display"]
                )

        with gr.Column(scale=2):
            gr.Markdown("### å¯¹è¯çª—å£")
            with gr.Row():
                more_files = gr.File(
                    label="è¿½åŠ ä¸Šä¼ æ–‡æ¡£ (æ”¯æŒå¤šé€‰)", file_types=[".txt", ".pdf", ".docx"], file_count="multiple"
                )
                more_files_btn = gr.Button("ä¸Šä¼ æ›´å¤šæ–‡æ¡£ï¼ˆè¿½åŠ åˆ°å½“å‰ç´¢å¼•ï¼‰", variant="secondary")
            more_status = gr.Markdown()

        gr.ChatInterface(
            fn=chat_with_agent,
            chatbot=gr.Chatbot(height=500, type="messages"),
            textbox=gr.Textbox(
                placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼š'ç‹ä¼Ÿçš„å¥—é¤æ˜¯ä»€ä¹ˆï¼Ÿ'", container=False, scale=7
            ),
            title=None,
            submit_btn="å‘é€",
            additional_inputs=[session_state],
        )

        process_button.click(
            fn=process_uploaded_file,
            inputs=[file_uploader, session_state, chunk_size, chunk_overlap, top_k, persist_dir],
            outputs=[status_display, result_display, process_button, session_state],
        )

        clear_cache_btn.click(
            fn=clear_cache,
            inputs=[persist_dir, session_state],
            outputs=[status_display, session_state],
        )

        more_files_btn.click(
            fn=process_more_files,
            inputs=[more_files, session_state, chunk_size, chunk_overlap, top_k, persist_dir],
            outputs=[more_status, session_state],
        )

        demo.queue()

    return demo